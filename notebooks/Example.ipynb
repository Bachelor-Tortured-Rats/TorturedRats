{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7531997-08a2-4af2-a309-ac61554a1449",
   "metadata": {},
   "source": [
    "# Example notebook of Unet segmentation model used in Bachelor Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c3b71-7af2-41a6-b903-4f7557925ed6",
   "metadata": {},
   "source": [
    "Requierements:\n",
    "* Computer needs lots of memory (preferably a100sh)\n",
    "* Plotly visualisations needs to be viewed locally as thinlink does not work great with rendering\n",
    "* Run notebook from base folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba977e8-4df5-40b2-8b98-1dd259d704d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Original script from: Vedrana Andersen Dahl\n",
    "###\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import skimage.measure\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (Activationsd, AsDiscreted, Compose,\n",
    "                              CropForegroundd, EnsureChannelFirstd, Invertd,\n",
    "                              LoadImaged, Orientationd, SaveImaged,\n",
    "                              ScaleIntensityRanged, Spacingd)\n",
    "from monai.utils import first, set_determinism\n",
    "from skimage.measure import label\n",
    "from skimage.transform import rescale\n",
    "from tqdm import tqdm\n",
    "\n",
    "import notebooks.volvizplotly as vvp\n",
    "from src.models.unet_model import load_unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4eba21e-94ef-4390-b95c-118b7504a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99acbfd9-f935-4402-9d66-70ce9dcc6c1e",
   "metadata": {},
   "source": [
    "## Predicting on rat kidney\n",
    "\n",
    "Loads images in with select preprossening\n",
    "Then saves the prediction mask in the original image format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8d83e7-647b-4408-b127-c5bc83e14086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_kidney(x):\n",
    "    return x == 1\n",
    "\n",
    "test_org_transforms_rats = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "        Orientationd(keys=[\"image\",'mask'], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"mask\"], pixdim=(0.0226, 0.0226, 0.0226), mode=(\"bilinear\", \"nearest\")),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"mask\"), \n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57, # model should be retrained with original range of 0 to 255, but to late now.\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "post_transforms_rats = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_org_transforms_rats,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        #AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
    "        Activationsd(keys=\"pred\", softmax=True), \n",
    "        AsDiscreted(keys=\"pred\", argmax=True),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir='notebooks', output_postfix=\"seg\", resample=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def save_prediction_masks(model, test_org_loader, post_transforms, device = 'cpu'):\n",
    "    \"\"\"\n",
    "    Runs inference with all images in test_org_loader, using model and applying post_transforms\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_data in tqdm(test_org_loader):\n",
    "            test_inputs = test_data[\"image\"]#.to(device)\n",
    "            roi_size = (160, 160, 160)\n",
    "            sw_batch_size = 4\n",
    "            # really slow 30 min on gpu\n",
    "            test_data[\"pred\"] = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model,sw_device=device,progress=True)\n",
    "\n",
    "            test_data = [post_transforms(i) for i in decollate_batch(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e5139-8495-43c1-9046-f1ee830afcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = 'models/finetune-kfold/model_16742264.pth'\n",
    "model, params = load_unet(model_load_path, device=device)\n",
    "\n",
    "train_images = ['/dtu/3d-imaging-center/projects/2020_QIM_22_rat_kidney/analysis/analysis_rat37/rat37_reorient.nii.gz']\n",
    "train_masks = ['/dtu/3d-imaging-center/projects/2020_QIM_22_rat_kidney/analysis/study_diabetic/aligned/rat37_aligned_rigid.nii']\n",
    "data_dicts = [{\"image\": image_name, \"mask\": train_mask} for image_name, train_mask in zip(train_images, train_masks)]\n",
    "\n",
    "print('Loading data (slow)')\n",
    "test_org_ds = Dataset(data=data_dicts, transform=test_org_transforms_rats)\n",
    "test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=0)\n",
    "print('Finished loading data')\n",
    "\n",
    "save_prediction_masks(model, test_org_loader, post_transforms_rats, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b8f16-db0a-4e6d-b4c4-c5a31552717f",
   "metadata": {},
   "source": [
    "## Visualises prediction\n",
    "HTML output needs to be opened in firefox on a local computer. \n",
    "Performance is slow with thinlinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6592d01-07a2-4c84-8566-01db8b79f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=-.6, y=2.1, z=.3)\n",
    ")\n",
    "\n",
    "# downscaled data for performance reasons\n",
    "downscale_coeff = 0.4\n",
    "anti_aliasing= False\n",
    "threshold = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103a7a29-040b-4a95-8572-38c660b2f097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/zhome/a2/4/155672/Desktop/Bachelor/TorturedRats\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a61ef60-ac60-4419-a71d-3017e58e5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads original image\n",
    "train_images = f'/dtu/3d-imaging-center/projects/2020_QIM_22_rat_kidney/analysis/analysis_rat37/rat37_reorient.nii.gz'\n",
    "train_labels = f'/dtu/3d-imaging-center/projects/2020_QIM_22_rat_kidney/analysis/analysis_rat37/vessel_zoom_ground_truth-ish_rat37_v2.nii.gz'\n",
    "train_masks = f'/dtu/3d-imaging-center/projects/2020_QIM_22_rat_kidney/analysis/study_diabetic/maskKidney/rat37_kidneyMaskProc.nii.gz'\n",
    "\n",
    "img = nib.load(train_images)\n",
    "img_mask = nib.load(train_masks)\n",
    "lab_true = nib.load(train_labels)\n",
    "#lab_pred = nib.load('notebooks/rat37_reorient/rat37_reorient_seg.nii.gz') # path to saved prediction mask that was generated before\n",
    "lab_pred = nib.load('reports/end/save_prediction_mask/16742264/rat37_reorient/rat37_reorient_seg.nii.gz') # path to saved prediction mask that was generated before\n",
    "\n",
    "# convert to arrays\n",
    "vol_fdata = np.array(img.get_fdata()).transpose((2, 1, 0))\n",
    "vol_mask_fdata = np.array(img_mask.get_fdata()).transpose((2, 1, 0))\n",
    "seg_true_fdata = np.array(lab_true.get_fdata()).transpose((2, 1, 0))\n",
    "lab_pred_fdata =  np.array(lab_pred.get_fdata()).transpose((2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5564da88-7d6f-4ae6-8dcf-c0422437e576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 rescale\n",
      "2/4 rescale\n",
      "3/4 rescale\n",
      "4/4 rescale\n"
     ]
    }
   ],
   "source": [
    "# rescales for visualisation\n",
    "vol = rescale(vol_fdata, downscale_coeff, anti_aliasing=anti_aliasing)\n",
    "print('1/4 rescale')\n",
    "vol_mask = rescale(vol_mask_fdata, downscale_coeff, anti_aliasing=anti_aliasing)\n",
    "print('2/4 rescale')\n",
    "seg_true = rescale(seg_true_fdata, downscale_coeff, anti_aliasing=anti_aliasing)\n",
    "print('3/4 rescale')\n",
    "#lab_pred = nib.load('reports/post/save_prediction_mask/posts/rat37_reorient/rat37_reorient_seg.nii.gz')\n",
    "lab_pred = rescale(lab_pred_fdata, downscale_coeff, anti_aliasing=anti_aliasing)\n",
    "print('4/4 rescale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "885c166e-4eef-4cdd-94be-89e26e165087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use marching cubes to obtain the surface mesh\n",
    "verts1, faces1, _, _ = skimage.measure.marching_cubes(seg_true!=0, 0.1)\n",
    "verts2, faces2, _, _ = skimage.measure.marching_cubes(lab_pred==1, 0.5)\n",
    "verts3, faces3, _, _ = skimage.measure.marching_cubes((seg_true!=0) & (lab_pred==1), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc8ff81-bd42-4a85-b1fc-ea04f72235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates plots\n",
    "fig = vvp.volume_slicer(vol, [None, 'mid', None], show=False, title='middle ct-slice',width=1200, height=1200)\n",
    "fig = vvp.show_mesh(verts1, faces1, fig=fig, show=False, surface_color='red', wireframe_opacity=.5,surface_opacity=.5,camera=camera)\n",
    "fig = vvp.show_mesh(verts2, faces2, fig=fig, show=False,surface_color='green', wireframe_opacity=.5,surface_opacity=.5)\n",
    "fig = vvp.show_mesh(verts3, faces3, fig=fig, show=False,surface_color='blue', wireframe_opacity=1,surface_opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05677073-dc1e-4eac-9f80-923f1d2a6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML output needs to be opened in firefox on a local computer. \n",
    "# Performance is slow with thinlinc\n",
    "fig.write_html('notebooks/16742264.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa29b34-ca68-4ded-b477-15d416500c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates plots (ONLY INFERENCE)\n",
    "fig = vvp.show_mesh(verts2, faces2, fig=None, show=False,surface_color='green', wireframe_opacity=.5,surface_opacity=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e063e4-916c-4f09-a62c-7c33589d4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML output needs to be opened in firefox on a local computer. \n",
    "# Performance is slow with thinlinc\n",
    "fig.write_html('notebooks/16742264_inf.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf25c9e-98e4-4150-8414-a72e2518d006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
